{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0bbb1546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7df7058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'data/600K US Housing Properties.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f87616c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_listings(df):\n",
    "    \n",
    "    return df.drop_duplicates(subset=['property_url', 'property_id'])\n",
    "df = remove_duplicate_listings(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4c37b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unwanted_columns(df):\n",
    "\n",
    "    columns_to_drop = ['apartment', 'listing_age', 'year_build', 'total_num_units', \n",
    "                       'agent_phone', 'agent_name', 'broker_id']\n",
    "    return df.drop(columns=columns_to_drop, errors='ignore')\n",
    "df = drop_unwanted_columns(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "eaf61291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/y7v21c5n7ld2752glwvsz5040000gn/T/ipykernel_7283/2612292687.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['street_name'].fillna(overall_mode, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_street_names(df):\n",
    "    \n",
    "    # Step 1: Fill using mode within 'postcode'\n",
    "    df['street_name'] = df['street_name'].fillna(\n",
    "        df.groupby('postcode')['street_name'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    )\n",
    "    \n",
    "    # Step 2: Fill using mode within 'city'\n",
    "    df['street_name'] = df['street_name'].fillna(\n",
    "        df.groupby('city')['street_name'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    )\n",
    "    \n",
    "    # Step 3: Fill with overall mode if still missing\n",
    "    if df['street_name'].isnull().any():\n",
    "        overall_mode = df['street_name'].mode().iloc[0]\n",
    "        df['street_name'].fillna(overall_mode, inplace=True)\n",
    "\n",
    "    return df\n",
    "df= fill_missing_street_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "722a0e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/y7v21c5n7ld2752glwvsz5040000gn/T/ipykernel_7283/954772271.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['city'].fillna(city_mode, inplace=True)\n",
      "/var/folders/sd/y7v21c5n7ld2752glwvsz5040000gn/T/ipykernel_7283/954772271.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['state'].fillna(state_mode, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_city_state(df):\n",
    "\n",
    "    # Fill city with its overall mode\n",
    "    if df['city'].isnull().any():\n",
    "        city_mode = df['city'].mode().iloc[0]\n",
    "        df['city'].fillna(city_mode, inplace=True)\n",
    "\n",
    "    # Fill state with its overall mode\n",
    "    if df['state'].isnull().any():\n",
    "        state_mode = df['state'].mode().iloc[0]\n",
    "        df['state'].fillna(state_mode, inplace=True)\n",
    "\n",
    "    return df\n",
    "df = fill_missing_city_state(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "151e4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_coordinates_by_location(df):\n",
    "    \"\"\"\n",
    "    Fills missing 'latitude' and 'longitude' values using:\n",
    "    1. Mode by 'postcode'\n",
    "    2. Mode by 'city' (fallback)\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing 'latitude', 'longitude', 'postcode', and 'city'\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with missing coordinates filled\n",
    "    \"\"\"\n",
    "    # Step 1: Fill latitude using postcode mode\n",
    "    df['latitude'] = df['latitude'].fillna(\n",
    "        df.groupby('postcode')['latitude'].transform(\n",
    "            lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 2: Fill longitude using postcode mode\n",
    "    df['longitude'] = df['longitude'].fillna(\n",
    "        df.groupby('postcode')['longitude'].transform(\n",
    "            lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 3: Fallback to city-level mode\n",
    "    df['latitude'] = df['latitude'].fillna(\n",
    "        df.groupby('city')['latitude'].transform(\n",
    "            lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "        )\n",
    "    )\n",
    "    df['longitude'] = df['longitude'].fillna(\n",
    "        df.groupby('city')['longitude'].transform(\n",
    "            lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan\n",
    "        )\n",
    "    )\n",
    "    return df\n",
    "df = fill_missing_coordinates_by_location(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fd29f007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 382 rows with invalid latitude or longitude.\n"
     ]
    }
   ],
   "source": [
    "def remove_invalid_coordinates(df):\n",
    "    \"\"\"\n",
    "    Removes rows with invalid latitude or longitude values.\n",
    "    Latitude must be between -90 and 90.\n",
    "    Longitude must be between -180 and 180.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with 'latitude' and 'longitude' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame with only valid coordinates.\n",
    "    \"\"\"\n",
    "    # Define valid coordinate range\n",
    "    valid_mask = df['latitude'].between(-90, 90) & df['longitude'].between(-180, 180)\n",
    "\n",
    "    # Report and remove invalid rows\n",
    "    invalid_count = (~valid_mask).sum()\n",
    "    if invalid_count > 0:\n",
    "        print(f\"Removed {invalid_count} rows with invalid latitude or longitude.\")\n",
    "    else:\n",
    "        print(\"All coordinates are within valid range.\")\n",
    "\n",
    "    # Return only valid rows\n",
    "    return df[valid_mask].copy()\n",
    "df=remove_invalid_coordinates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d115d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_postcodes(df):\n",
    "    \"\"\"\n",
    "    Fills missing postcode values by:\n",
    "    1. Using the mode of postcode within the same city.\n",
    "    2. If still missing, uses the mode within the same state.\n",
    "    3. Prints how many postcodes were still missing (if any).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'postcode', 'city', and 'state' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with missing postcodes filled where possible.\n",
    "    \"\"\"\n",
    "    # Step 1: Fill with mode by city\n",
    "    df['postcode'] = df['postcode'].fillna(\n",
    "        df.groupby('city')['postcode'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    )\n",
    "\n",
    "    # Step 2: Fill remaining with mode by state\n",
    "    df['postcode'] = df['postcode'].fillna(\n",
    "        df.groupby('state')['postcode'].transform(lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df=fill_missing_postcodes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0f0c14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_lot_beds_baths(df):\n",
    "    \"\"\"\n",
    "    For properties of type 'LOT', fills missing values in bedroom_number and bathroom_number with 0.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'property_type', 'bedroom_number', and 'bathroom_number'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with LOT bedrooms/bathrooms filled as 0.\n",
    "    \"\"\"\n",
    "    lot_mask = df['property_type'] == 'LOT'\n",
    "\n",
    "    # Fill missing values with 0 only for 'LOT' property type\n",
    "    df.loc[lot_mask, 'bedroom_number'] = df.loc[lot_mask, 'bedroom_number'].fillna(0)\n",
    "    df.loc[lot_mask, 'bathroom_number'] = df.loc[lot_mask, 'bathroom_number'].fillna(0)\n",
    "    return df\n",
    "df = fill_lot_beds_baths(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "04a39adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_beds_baths_by_property_type(df):\n",
    "    \"\"\"\n",
    "    For all non-LOT property types, fills missing bedroom_number and bathroom_number\n",
    "    using the median values grouped by property_type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'property_type', 'bedroom_number', and 'bathroom_number'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with missing values filled by type-wise median.\n",
    "    \"\"\"\n",
    "    # Exclude LOT properties\n",
    "    non_lot_mask = df['property_type'] != 'LOT'\n",
    "\n",
    "    # Fill bedroom_number\n",
    "    df.loc[non_lot_mask, 'bedroom_number'] = df.loc[non_lot_mask].groupby('property_type')['bedroom_number'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    # Fill bathroom_number\n",
    "    df.loc[non_lot_mask, 'bathroom_number'] = df.loc[non_lot_mask].groupby('property_type')['bathroom_number'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "    return df\n",
    "df = fill_beds_baths_by_property_type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "edc0a73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_url               0\n",
       "property_id                0\n",
       "address                    0\n",
       "street_name                0\n",
       "city                       0\n",
       "state                      0\n",
       "latitude                   0\n",
       "longitude                  0\n",
       "postcode                   0\n",
       "price                      0\n",
       "bedroom_number             0\n",
       "bathroom_number            0\n",
       "price_per_unit        164321\n",
       "living_space          151874\n",
       "land_space             84872\n",
       "land_space_unit        84872\n",
       "property_type              0\n",
       "property_status            0\n",
       "RunDate                    0\n",
       "agency_name           155330\n",
       "is_owned_by_zillow         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "851f46d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_price_per_unit(df):\n",
    "    \"\"\"\n",
    "    Fills missing values in the 'price_per_unit' column:\n",
    "    1. First by calculating price / living_space (if both are available).\n",
    "    2. Then by using the median price_per_unit grouped by property_type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing 'price', 'living_space', 'price_per_unit', 'property_type'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with filled 'price_per_unit'.\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate price_per_unit from price / living_space\n",
    "    missing_ppu = df['price_per_unit'].isnull()\n",
    "\n",
    "    df.loc[missing_ppu, 'price_per_unit'] = df.loc[missing_ppu].apply(\n",
    "        lambda row: row['price'] / row['living_space']\n",
    "        if pd.notnull(row['price']) and pd.notnull(row['living_space']) and row['living_space'] != 0\n",
    "        else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Step 2: Fill remaining with median by property_type\n",
    "    df['price_per_unit'] = df['price_per_unit'].fillna(\n",
    "        df.groupby('property_type')['price_per_unit'].transform(lambda x: x.median())\n",
    "    )\n",
    "\n",
    "    return df\n",
    "df = fill_price_per_unit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d7b63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_living_space_for_lots(df):\n",
    "    \"\"\"\n",
    "    Sets missing 'living_space' to 0 for properties with type 'LOT',\n",
    "    since vacant land should not have built area.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'property_type' and 'living_space'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with 'living_space' filled for LOTs.\n",
    "    \"\"\"\n",
    "    lot_mask = (df['property_type'] == 'LOT') & (df['living_space'].isnull())\n",
    "    df.loc[lot_mask, 'living_space'] = 0\n",
    "    return df\n",
    "df = set_living_space_for_lots(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8c84d7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_living_space_by_property_type(df):\n",
    "    \"\"\"\n",
    "    Fills missing 'living_space' for non-LOT properties using median per property_type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'property_type' and 'living_space'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with filled 'living_space'.\n",
    "    \"\"\"\n",
    "    # Only for non-LOT properties\n",
    "    non_lot_mask = df['property_type'] != 'LOT'\n",
    "\n",
    "    # Fill missing values with group-wise median\n",
    "    df.loc[non_lot_mask, 'living_space'] = df.loc[non_lot_mask].groupby('property_type')['living_space'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    return df\n",
    "df = fill_living_space_by_property_type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a672a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_land_space_for_condo_apartment(df):\n",
    "    \"\"\"\n",
    "    Sets missing 'land_space' to 0 for properties of type CONDO and APARTMENT.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'property_type' and 'land_space'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with missing land_space filled as 0 for applicable types.\n",
    "    \"\"\"\n",
    "    mask = df['property_type'].isin(['CONDO', 'APARTMENT']) & df['land_space'].isnull()\n",
    "    df.loc[mask, 'land_space'] = 0\n",
    "\n",
    "    return df\n",
    "df = fill_land_space_for_condo_apartment(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b5b5dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_land_space_by_property_type(df):\n",
    "    \"\"\"\n",
    "    Fills missing 'land_space' for non-CONDO and non-APARTMENT properties\n",
    "    using the median land_space grouped by property_type.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'property_type' and 'land_space'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with filled 'land_space'.\n",
    "    \"\"\"\n",
    "    # Define types that need to be filled with median (i.e., NOT condo/apartment)\n",
    "    types_needing_median = ['SINGLE_FAMILY', 'MULTI_FAMILY', 'TOWNHOUSE', 'MANUFACTURED', 'LOT']\n",
    "\n",
    "    # Filter mask\n",
    "    mask = df['property_type'].isin(types_needing_median) & df['land_space'].isnull()\n",
    "\n",
    "    # Apply median fill per property type\n",
    "    df.loc[mask, 'land_space'] = df.loc[mask].groupby('property_type')['land_space'].transform(\n",
    "        lambda x: x.fillna(x.median())\n",
    "    )\n",
    "\n",
    "    return df\n",
    "df = fill_land_space_by_property_type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b9a3eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_land_space_with_overall_median(df):\n",
    "    \"\"\"\n",
    "    Fills all remaining missing values in 'land_space' using the overall median of the column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'land_space'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with all missing 'land_space' filled.\n",
    "    \"\"\"\n",
    "    overall_median_land = df['land_space'].median()\n",
    "    missing_count = df['land_space'].isnull().sum()\n",
    "\n",
    "    df['land_space'] = df['land_space'].fillna(overall_median_land)\n",
    "\n",
    "    return df\n",
    "df = fill_land_space_with_overall_median(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "932f1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_land_space_unit_with_mode(df):\n",
    "    \"\"\"\n",
    "    Fills missing 'land_space_unit' values with the most frequent (mode) value.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame with 'land_space_unit'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with missing 'land_space_unit' filled.\n",
    "    \"\"\"\n",
    "    mode_unit = df['land_space_unit'].mode()\n",
    "    if not mode_unit.empty:\n",
    "        fill_value = mode_unit[0]\n",
    "        missing_count = df['land_space_unit'].isnull().sum()\n",
    "        df['land_space_unit'] = df['land_space_unit'].fillna(fill_value)\n",
    "    \n",
    "    return df\n",
    "df = fill_land_space_unit_with_mode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_agency_name_with_unknown(df):\n",
    "\n",
    "    df[\"RunDate\"] = pd.to_datetime(df[\"RunDate\"]).dt.date\n",
    "\n",
    "    missing_count = df['agency_name'].isnull().sum()\n",
    "    df['agency_name'] = df['agency_name'].fillna(\"Unknown\")\n",
    "    return df\n",
    "df = fill_agency_name_with_unknown(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45b739fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_url          0\n",
       "property_id           0\n",
       "address               0\n",
       "street_name           0\n",
       "city                  0\n",
       "state                 0\n",
       "latitude              0\n",
       "longitude             0\n",
       "postcode              0\n",
       "price                 0\n",
       "bedroom_number        0\n",
       "bathroom_number       0\n",
       "price_per_unit        0\n",
       "living_space          0\n",
       "land_space            0\n",
       "land_space_unit       0\n",
       "property_type         0\n",
       "property_status       0\n",
       "RunDate               0\n",
       "agency_name           0\n",
       "is_owned_by_zillow    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1b7a0f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported successfully to:\n",
      "/Users/kittu/Downloads/live property search/data/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define export path\n",
    "export_path = '/Users/kittu/Downloads/live property search/data/cleaned_data.csv'\n",
    "\n",
    "# Export DataFrame as CSV\n",
    "df.to_csv(export_path, index=False)\n",
    "\n",
    "print(f\"Data exported successfully to:\\n{export_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "827d1cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "property_id             int64\n",
       "property_url           object\n",
       "address                object\n",
       "street_name            object\n",
       "city                   object\n",
       "state                  object\n",
       "postcode                int64\n",
       "latitude              float64\n",
       "longitude             float64\n",
       "price                 float64\n",
       "bedroom_number          int64\n",
       "bathroom_number         int64\n",
       "price_per_unit        float64\n",
       "living_space          float64\n",
       "land_space            float64\n",
       "land_space_unit        object\n",
       "property_type          object\n",
       "property_status        object\n",
       "RunDate                object\n",
       "agency_name            object\n",
       "is_owned_by_zillow       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6ceb97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_column_types(df):\n",
    "    \"\"\"\n",
    "    Converts column types:\n",
    "    - postcode, bedroom_number, bathroom_number to integers\n",
    "    - is_owned_by_zillow to boolean\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with proper types\n",
    "    \"\"\"\n",
    "    # Convert to integer safely (handle NaNs)\n",
    "    for col in ['postcode', 'bedroom_number', 'bathroom_number']:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Convert is_owned_by_zillow to boolean\n",
    "    df['is_owned_by_zillow'] = df['is_owned_by_zillow'].astype(bool)\n",
    "\n",
    "    return df\n",
    "df = convert_column_types(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea5793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-9.3.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (7.5 kB)\n",
      "Downloading mysql_connector_python-9.3.0-cp312-cp312-macosx_14_0_arm64.whl (15.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-9.3.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fc51e69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully!\n",
      "Table 'HouseData' is ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/y7v21c5n7ld2752glwvsz5040000gn/T/ipykernel_7283/3882475894.py:76: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 599618 rows into 'HouseData' table.\n",
      "Connection closed.\n",
      "Data export completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from config import DB_CONFIG\n",
    "\n",
    "def db_connection():\n",
    "    \"\"\"\n",
    "    Create and return a MySQL database connection\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (connection, cursor) if successful, (None, None) if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to MySQL using config\n",
    "        conn = mysql.connector.connect(\n",
    "            host=DB_CONFIG['host'],\n",
    "            user=DB_CONFIG['username'],\n",
    "            password=DB_CONFIG['password'],\n",
    "            database=DB_CONFIG['database'],\n",
    "            port=DB_CONFIG['port']\n",
    "        )\n",
    "        \n",
    "        if conn.is_connected():\n",
    "            print(\"Connection established successfully!\")\n",
    "            cursor = conn.cursor()\n",
    "            return conn, cursor\n",
    "        else:\n",
    "            print(\"Failed to connect to MySQL.\")\n",
    "            return None, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def data_export(conn, cursor, csv_path=\"data/cleaned_data.csv\"):\n",
    "    \"\"\"\n",
    "    Export data from CSV to MySQL HouseData table\n",
    "    \n",
    "    Args:\n",
    "        conn: MySQL connection object\n",
    "        cursor: MySQL cursor object\n",
    "        csv_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create Table (if not exists)\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS HouseData (\n",
    "            property_id VARCHAR(100) PRIMARY KEY,\n",
    "            property_url TEXT,\n",
    "            address TEXT,\n",
    "            street_name TEXT,\n",
    "            city VARCHAR(100),\n",
    "            state VARCHAR(50),\n",
    "            postcode VARCHAR(20),\n",
    "            latitude DOUBLE,\n",
    "            longitude DOUBLE,\n",
    "            price DOUBLE,\n",
    "            bedroom_number INT,\n",
    "            bathroom_number INT,\n",
    "            price_per_unit DOUBLE,\n",
    "            living_space DOUBLE,\n",
    "            land_space DOUBLE,\n",
    "            land_space_unit VARCHAR(20),\n",
    "            property_type VARCHAR(50),\n",
    "            property_status VARCHAR(50),\n",
    "            RunDate DATE,\n",
    "            agency_name VARCHAR(255),\n",
    "            is_owned_by_zillow BOOLEAN\n",
    "        );\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        print(\"Table 'HouseData' is ready.\")\n",
    "        \n",
    "        # Load Cleaned CSV into DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Reorder columns to match SQL insert\n",
    "        columns = [\n",
    "            \"property_id\", \"property_url\", \"address\", \"street_name\", \"city\", \"state\", \"postcode\",\n",
    "            \"latitude\", \"longitude\", \"price\", \"bedroom_number\", \"bathroom_number\",\n",
    "            \"price_per_unit\", \"living_space\", \"land_space\", \"land_space_unit\",\n",
    "            \"property_type\", \"property_status\", \"RunDate\", \"agency_name\", \"is_owned_by_zillow\"\n",
    "        ]\n",
    "        df = df[columns]\n",
    "        \n",
    "        # Prepare insert query\n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO HouseData (\n",
    "            property_id, property_url, address, street_name, city, state, postcode,\n",
    "            latitude, longitude, price, bedroom_number, bathroom_number,\n",
    "            price_per_unit, living_space, land_space, land_space_unit,\n",
    "            property_type, property_status, RunDate, agency_name, is_owned_by_zillow\n",
    "        ) VALUES (\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples (handle NaNs)\n",
    "        data = df.where(pd.notnull(df), None).values.tolist()\n",
    "        \n",
    "        # Insert all rows\n",
    "        cursor.executemany(insert_query, data)\n",
    "        conn.commit()\n",
    "        print(f\"Inserted {cursor.rowcount} rows into 'HouseData' table.\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Data export error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        return False\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Establish connection\n",
    "    conn, cursor = db_connection()\n",
    "    \n",
    "    if conn and cursor:\n",
    "        # Step 2: Export data\n",
    "        success = data_export(conn, cursor)\n",
    "        \n",
    "        # Step 3: Clean up\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        print(\"Connection closed.\")\n",
    "        \n",
    "        if success:\n",
    "            print(\"Data export completed successfully!\")\n",
    "        else:\n",
    "            print(\"Data export failed!\")\n",
    "    else:\n",
    "        print(\"Could not establish database connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80e7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
